{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3d4e294d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 players 24 cards in deck 4 0 trump\n",
      "[]\n",
      "['[26, 15, 8, 5, 20, 10] [8 6 8 5 2 1]', '[2, 24, 16, 28, 13, 23] [2 6 7 1 4 5]']\n",
      "1 attacker 0 defender\n",
      "\n",
      "2 players 23 cards in deck 20 2 trump\n",
      "[[2, None]]\n",
      "['[14, 19, 7, 4, 27, 0] [5 1 7 4 0 0]', '[12, 13, 18, 3, 16, 17] [3 4 0 3 7 8]']\n",
      "0 attacker 1 defender\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def getSuit(card):\n",
    "    return np.floor(card/9).astype('int')\n",
    "\n",
    "def getRank(card):\n",
    "    return np.floor(card%9).astype('int')\n",
    "        \n",
    "def getLastAction(player):\n",
    "    return player.actions[-1].verb if len(player.actions) > 0 else None\n",
    "\n",
    "def getNumCardsOnBoard(board):\n",
    "    c = 0\n",
    "    for pair in board:\n",
    "        c += len(pair)\n",
    "    return c\n",
    "\n",
    "def getNumNotCovered(board):\n",
    "    c = 0\n",
    "    for a,b in board:\n",
    "        if b == None:\n",
    "            c += 1\n",
    "    return c\n",
    "\n",
    "def getNotCoveredBoardId(board, target):\n",
    "    for i,(a,b) in enumerate(board):\n",
    "        if a == target and b == None:\n",
    "            return i\n",
    "    return -1\n",
    "\n",
    "def boardAttacksAllSameRank(board):\n",
    "    # Empty board is all same rank for learning penalty purposes\n",
    "    # Was assert\n",
    "    if len(board) == 0:\n",
    "        return True\n",
    "    r = getRank(board[0][0])\n",
    "    for a,b in board:\n",
    "        if r != getRank(a):\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "def beats(over, under, trump):\n",
    "    if getSuit(over) == getSuit(under):\n",
    "        return getRank(over) > getRank(under)\n",
    "    if getSuit(over) == getSuit(trump):\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def allPass(players):\n",
    "    for p in playrs:\n",
    "        if getLastAction(p) != 'pass':\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "def rankOnBoard(board, card):\n",
    "    r = getRank(card)\n",
    "    for a,b in board:\n",
    "        if getRank(a) == r and getRank(b) == r:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "class Player:\n",
    "    def __init__(self):\n",
    "        self.hand = []\n",
    "        self.actions = []\n",
    "        \n",
    "    def __str__(self):\n",
    "        return f'{self.hand} {getRank(np.array(self.hand))}'\n",
    "        \n",
    "class Action:\n",
    "    def __init__(self, player, defender, verb, card=None, target=None):\n",
    "        self.player = player\n",
    "        self.defender = defender\n",
    "        self.verb = verb\n",
    "        self.card = card\n",
    "        self.target = target\n",
    "\n",
    "class Game:\n",
    "    def __init__(self, nPlayers):\n",
    "        self.players = [Player() for i in range(nPlayers)]\n",
    "        self.deck = np.arange(36)\n",
    "        np.random.shuffle(self.deck)\n",
    "        self.discard = []\n",
    "        self.board = []\n",
    "        self.trump = self.deck[0]\n",
    "        self.attacker = self.players[0]\n",
    "        self.defender = self.players[1]\n",
    "        self.deal()\n",
    "        self.attacker = self.getFirstAttacker()\n",
    "        self.defender = self.players[(self.players.index(self.attacker)+1)%len(self.players)]\n",
    "        self.turn = 0\n",
    "        \n",
    "    def __str__(self):\n",
    "        return f'''{len(self.players)} players {len(self.deck)} cards in deck {self.trump} {getSuit(self.trump)} trump\n",
    "{self.board}\n",
    "{[str(p) for p in self.players]}\n",
    "{self.players.index(self.attacker)} attacker {self.players.index(self.defender)} defender\n",
    "'''\n",
    "        \n",
    "    def deal(self):\n",
    "        d = self.getDirection()\n",
    "        n = len(self.players)\n",
    "        i = self.players.index(self.defender)+n\n",
    "        dealOrder = np.arange(3*n)\n",
    "        dealOrder = dealOrder[i:i+d*n:d]\n",
    "        for i in dealOrder:\n",
    "            h = self.players[i%n].hand\n",
    "            m = 6-len(h)\n",
    "            h[len(h):] = self.deck[len(self.deck)-1:len(self.deck)-m-1:-1]\n",
    "            self.deck = self.deck[:len(self.deck)-m]\n",
    "    \n",
    "    def randomState(self):\n",
    "        # Choose attacker and defender\n",
    "        idx = np.random.randint(0,len(self.players))\n",
    "        direc = np.random.randint(0,2)*2-1\n",
    "        self.attacker = self.players[idx]\n",
    "        self.defender = self.players[(idx+direc)%len(self.players)]\n",
    "        # Random deck, trump, and random number of cards\n",
    "        self.deck = np.arange(36)\n",
    "        np.random.shuffle(self.deck)\n",
    "        self.trump = self.deck[0]\n",
    "        for i in range(len(self.players)):\n",
    "            self.players[i].hand = []\n",
    "            if np.random.rand() < 0.2:\n",
    "                nc = np.random.randint(0,7)\n",
    "            else:\n",
    "                nc = np.random.randint(6,7)\n",
    "            self.players[i].hand[:nc] = self.deck[len(self.deck)-1:len(self.deck)-1-nc:-1]\n",
    "            self.deck = self.deck[:len(self.deck)-nc]\n",
    "        # Random board (actual covers don't make sense)\n",
    "        nc = np.random.randint(0,5)\n",
    "        self.board = []\n",
    "        for i in range(nc):\n",
    "            if np.random.randint(0,2) == 0:\n",
    "                self.board.append([self.deck[-1], None])\n",
    "                self.deck = self.deck[:-1]\n",
    "            else:\n",
    "                self.board.append([self.deck[-1], self.deck[-2]])\n",
    "                self.deck = self.deck[:-2]\n",
    "        \n",
    "    def getDirection(self):\n",
    "        i = self.players.index(self.defender)\n",
    "        j = self.players.index(self.attacker)\n",
    "        d = i-j\n",
    "        if abs(d) == 1:\n",
    "            return d\n",
    "        if i == 0 and j == len(self.players)-1:\n",
    "            return 1\n",
    "        if i == len(self.players)-1 and j == 0:\n",
    "            return -1\n",
    "        assert False\n",
    "    \n",
    "    def getFirstAttacker(self):\n",
    "        s = getSuit(self.trump)\n",
    "        m = np.zeros([len(self.players),2])\n",
    "        for i,p in enumerate(self.players):\n",
    "            h = np.array(p.hand)\n",
    "            m[i,1] = np.amin(h%9)\n",
    "            h[getSuit(h) != s] = 100\n",
    "            m[i,0] = np.amin(h)\n",
    "        if np.min(m[:,0]) < 100:\n",
    "            return self.players[np.argmin(m[:,0])]\n",
    "        else:\n",
    "            return self.players[np.argmin(m[:,1])]\n",
    "        \n",
    "    def action(self, e):\n",
    "        reward = torch.zeros(5).float().cuda()\n",
    "        if e.player < len(self.players):\n",
    "            reward[0] = 10\n",
    "        else:\n",
    "            return reward\n",
    "        p = self.players[e.player]\n",
    "        if e.defender == self.players.index(self.defender):\n",
    "            reward[1] = 10\n",
    "        if p == self.defender:\n",
    "            if getLastAction(p) == 'pickup':\n",
    "                return reward\n",
    "            if e.verb in ['reverse', 'cover', 'pickup']:\n",
    "                reward[2] = 10\n",
    "            if e.verb == 'reverse':\n",
    "                if p.hand.count(e.card) > 0:\n",
    "                    reward[3] = 10\n",
    "                if e.target is None:\n",
    "                    reward[4] = 10\n",
    "                if len(self.board) == 0:\n",
    "                    reward[2] -= 2\n",
    "                if getNumNotCovered(self.board) < len(self.board):\n",
    "                    reward[2] -= 2\n",
    "                if not boardAttacksAllSameRank(self.board):\n",
    "                    reward[2] -= 2\n",
    "                if len(self.board) > 0 and getRank(self.board[0][0]) != getRank(e.card):\n",
    "                    reward[3] -= 2\n",
    "                #board.append([e.card])\n",
    "                #p.hand.remove(e.card)\n",
    "                #self.attacker, self.defender = self.defender, self.attacker\n",
    "                #p.actions.append(e)\n",
    "            elif e.verb == 'cover':\n",
    "                if p.hand.count(e.card) > 0:\n",
    "                    reward[3] = 10\n",
    "                if e.target is not None:\n",
    "                    reward[4] = 10\n",
    "                if e.card is not None and e.target is not None and not beats(e.card, e.target, self.trump):\n",
    "                    reward[3] -= 2\n",
    "                    reward[4] -= 2\n",
    "                boardId = getNotCoveredBoardId(self.board, e.target)\n",
    "                if boardId == -1:\n",
    "                    reward[4] -= 2\n",
    "                #self.board[boardId][1] = e.card\n",
    "                #p.hand.remove(e.card)\n",
    "                #p.actions.append(e)\n",
    "            elif e.verb == 'pickup':\n",
    "                if e.card is None:\n",
    "                    reward[3] = 10\n",
    "                if e.target is None:\n",
    "                    reward[4] = 10\n",
    "                #p.actions.append(e)\n",
    "        else:\n",
    "            if e.verb in ['play', 'pass']:\n",
    "                reward[2] = 10\n",
    "            if e.verb == 'play':\n",
    "                if p.hand.count(e.card) > 0:\n",
    "                    reward[3] = 10\n",
    "                if e.target is None:\n",
    "                    reward[4] = 10\n",
    "                if getNumNotCovered(self.board) > len(self.defender.hand):\n",
    "                    reward[2] -= 2\n",
    "                if (len(self.board) == 0 and p == self.attacker) or rankOnBoard(self.board, e.card):\n",
    "                    #p.hand.remove(e.card)\n",
    "                    #p.actions.append(e)\n",
    "                    pass\n",
    "                else:\n",
    "                    reward[3] -= 2\n",
    "            elif e.verb == 'pass':\n",
    "                if e.card is None:\n",
    "                    reward[3] = 10\n",
    "                if e.target is None:\n",
    "                    reward[4] = 10\n",
    "                #p.actions.append(e)\n",
    "        return reward\n",
    "    \n",
    "g = Game(2)\n",
    "print(g)\n",
    "\n",
    "g.randomState()\n",
    "print(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a5918ab1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([10., 10., 10., -2., 10.], device='cuda:0')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g.action(Action(0,1,'play',32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6fd323a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[2, None]]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g.board"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "id": "cf0bbea4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complete\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch_geometric.nn.dense import DenseGraphConv\n",
    "\n",
    "def maskDiag(mat):\n",
    "    return mat*(1-torch.eye(mat.shape[0]).float().cuda())\n",
    "\n",
    "class DurakBoard(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DurakBoard, self).__init__()\n",
    "        # p is short for pairs\n",
    "        self.p0 = DenseGraphConv(37+37,200).float().cuda()\n",
    "        \n",
    "    def forward(self, board):\n",
    "        p = torch.zeros(len(board)+1,37*2).float().cuda()\n",
    "        \n",
    "        for i,(a,b) in enumerate(board):\n",
    "            p[i,a] = 1\n",
    "            if b is not None:\n",
    "                p[i,37+b] = 1\n",
    "            else:\n",
    "                p[i,37+36] = 1\n",
    "        \n",
    "        # Last position is readout\n",
    "        p[len(board),:] = 1\n",
    "        \n",
    "        Ap = maskDiag(torch.ones(2*[p.shape[0]]).float().cuda())/p.shape[0]\n",
    "        \n",
    "        p = self.p0(p,Ap).squeeze(0)\n",
    "        \n",
    "        return p[-1]\n",
    "        \n",
    "class DurakQueryCardsBoard(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DurakQueryCardsBoard, self).__init__()\n",
    "        self.fc0 = nn.Linear(200,36).float().cuda()\n",
    "        \n",
    "    def forward(self, board):\n",
    "        x = self.fc0(board)\n",
    "        return x\n",
    "\n",
    "durakBoard = DurakBoard()\n",
    "durakQueryCardsBoard = DurakQueryCardsBoard()\n",
    "\n",
    "optim = torch.optim.Adam([{'params': mod.parameters()} for mod in [durakBoard, durakQueryCardsBoard]], \n",
    "                         lr=1e-4, weight_decay=0)\n",
    "\n",
    "print('Complete')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "id": "57cd0ab1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complete\n"
     ]
    }
   ],
   "source": [
    "torch.save(durakBoard, 'DurakBoard.pyt')\n",
    "torch.save(durakQueryCardsBoard, 'DurakQueryCardsBoard.pyt')\n",
    "\n",
    "print('Complete')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "id": "dba28481",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(4., device='cuda:0')\n",
      "tensor([[0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "       device='cuda:0')\n",
      "tensor([[0.0233, 0.0233, 0.0233, 0.0233, 0.0233, 0.0634, 0.0233, 0.0634, 0.0233,\n",
      "         0.0233, 0.0233, 0.0233, 0.0233, 0.0233, 0.0233, 0.0233, 0.0233, 0.0233,\n",
      "         0.0233, 0.0233, 0.0233, 0.0233, 0.0233, 0.0233, 0.0634, 0.0634, 0.0233,\n",
      "         0.0233, 0.0233, 0.0233, 0.0233, 0.0233, 0.0233, 0.0233, 0.0233, 0.0233]],\n",
      "       device='cuda:0')\n",
      "tensor(3.5128, device='cuda:0')\n",
      "tensor(36., device='cuda:0')\n",
      "tensor(36., device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "def recalcTgt():\n",
    "    tgt = torch.zeros(1,36).float().cuda()\n",
    "    card = torch.zeros(36,36).float().cuda()\n",
    "    location = torch.zeros(36,1).float().cuda()\n",
    "\n",
    "    idx = 0\n",
    "    for c in range(36):\n",
    "        for loc in range(1):\n",
    "            card[idx,c] = 1\n",
    "            location[idx,loc] = 1\n",
    "            idx += 1\n",
    "            for a,b in g.board:\n",
    "                if a == c or b == c:\n",
    "                    tgt[0,c] = 1\n",
    "    \n",
    "    return tgt, card, location\n",
    "\n",
    "tgt, card, location = recalcTgt()\n",
    "\n",
    "def multiCrossEntropyLoss(inp, tgt):\n",
    "    A = torch.exp(inp)*tgt\n",
    "    B = torch.exp(-inp)*(1-tgt)\n",
    "    C = torch.exp(-inp)*tgt\n",
    "    D = torch.exp(inp)*(1-tgt)\n",
    "    return torch.log(torch.sum((C+D)/(A+B))+1)\n",
    "\n",
    "print(torch.sum(tgt))\n",
    "print(tgt)\n",
    "print(tgt.softmax(dim=1))\n",
    "print(multiCrossEntropyLoss(tgt, tgt))\n",
    "print(torch.sum(card))\n",
    "print(torch.sum(location))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "id": "342fd36d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0016, device='cuda:0')\n",
      "tensor([[0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "       device='cuda:0')\n",
      "tensor([[-5., -5., -5., -5., -5.,  5., -5.,  5., -5., -5., -5., -5., -5., -5.,\n",
      "         -5., -5., -5., -5., -5., -5., -5., -5., -5., -5.,  5.,  5., -5., -5.,\n",
      "         -5., -5., -5., -5., -5., -5., -5., -5.]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "tgta = tgt.detach().clone()\n",
    "tgta[tgt == 0] = -5\n",
    "tgta[tgt > 0] = 5\n",
    "print(multiCrossEntropyLoss(tgta, tgt))\n",
    "print(tgt)\n",
    "print(tgta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "id": "a410a9ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[20, None], [35, None], [34, 14]]\n",
      "tensor(0.8397, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "g.randomState()\n",
    "tgt, card, location = recalcTgt()\n",
    "print(g.board)\n",
    "print(multiCrossEntropyLoss(tgt, tgt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "id": "fe3b60e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
      "         0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1.]],\n",
      "       device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(tgt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "id": "4b29fa41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 loss 0.0002574589161667973 nReset 0\n",
      "epoch 1000 loss 3.2543604902457446e-05 nReset 973\n",
      "epoch 2000 loss 2.5033637939486653e-05 nReset 988\n",
      "epoch 3000 loss 2.658331868587993e-05 nReset 997\n",
      "epoch 4000 loss 0.0005138983833603561 nReset 965\n",
      "epoch 5000 loss 0.0002686616498976946 nReset 999\n",
      "epoch 6000 loss 1.4781842764932662e-05 nReset 1000\n",
      "epoch 7000 loss 0.002256944077089429 nReset 1000\n",
      "epoch 8000 loss 0.001392586505971849 nReset 1000\n",
      "epoch 9000 loss 0.001650877296924591 nReset 1000\n",
      "epoch 10000 loss 0.00016544880054425448 nReset 1000\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_2190/1537762421.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m1e-2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandomState\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m         \u001b[0mtgt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcard\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrecalcTgt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m         \u001b[0mnReset\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_2190/1097974940.py\u001b[0m in \u001b[0;36mrecalcTgt\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m36\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mloc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m             \u001b[0mcard\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m             \u001b[0mlocation\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m             \u001b[0midx\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "nEpochs = 500_000\n",
    "running = []\n",
    "pPeriod = 1000\n",
    "window = 100\n",
    "nReset = 0\n",
    "\n",
    "lossFn = nn.CrossEntropyLoss()\n",
    "\n",
    "for epoch in range(nEpochs):\n",
    "    optim.zero_grad()\n",
    "    b = durakBoard(g.board)\n",
    "    res = durakQueryCardsBoard(b).unsqueeze(0)\n",
    "    loss = multiCrossEntropyLoss(res, tgt)\n",
    "    loss.backward()\n",
    "    optim.step()\n",
    "#     running.append(loss)\n",
    "#     if len(running) == window:\n",
    "#         running.pop(0)\n",
    "    if epoch % pPeriod == 0 or epoch == nEpochs-1:\n",
    "        print(f'epoch {epoch} loss {loss} nReset {nReset}')\n",
    "        nReset = 0\n",
    "    if loss < 1e-2:\n",
    "        g.randomState()\n",
    "        tgt, card, location = recalcTgt()\n",
    "        nReset += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "id": "5f70d11a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-5.7436, -6.0122, -6.1552, -5.3784, -6.1279, -5.5721, -5.6316, -6.6657,\n",
      "         -4.7557, -6.0169,  7.8229, -5.4099, -5.3436, -5.6879, -6.1757,  6.5619,\n",
      "         -6.2521, -5.8146, -6.5479,  7.2914, -5.8215, -6.0255, -6.3573, -5.8374,\n",
      "          7.6083, -5.4972, -6.0702, -6.3186,  6.6246, -6.5314, -5.0410, -5.6181,\n",
      "         -6.5129, -5.8469, -5.5663,  7.4019],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000,  0.0000,  1.0000,  0.0000,  0.0000,  0.0000,  0.0000,  1.0000,\n",
      "          0.0000,  0.0000,  0.0000,  1.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          1.0000,  0.0000,  0.0000,  0.0000,  1.0000,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000,  0.0000,  0.0000,  1.0000]], device='cuda:0',\n",
      "       grad_fn=<CatBackward0>)\n",
      "tensor(0.0004, device='cuda:0', grad_fn=<LogBackward0>)\n"
     ]
    }
   ],
   "source": [
    "g.randomState()\n",
    "b = durakBoard(g.board).unsqueeze(0)\n",
    "tgt, card, location = recalcTgt()\n",
    "res = durakQueryCardsBoard(b)\n",
    "print(torch.cat([res, tgt], dim=0))\n",
    "print(multiCrossEntropyLoss(res, tgt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d514e97",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.distributions import Categorical, OneHotCategorical\n",
    "\n",
    "verbs = ['reverse','cover','pickup','play','pass']\n",
    "\n",
    "def makeAction(x):\n",
    "    mod = [Categorical(logits=x) for x in [x[:6], x[6:12], x[12:17], x[17:17+37], x[17+37:]]]\n",
    "    act = [m.sample() for m in mod] \n",
    "    me = int(act[0])\n",
    "    defender = int(act[1])\n",
    "    verb = verbs[act[2]]\n",
    "    card = int(act[3])\n",
    "    target = int(act[4])\n",
    "    if card == 36:\n",
    "        card = None\n",
    "    if target == 36:\n",
    "        target = None\n",
    "    return Action(me, defender, verb, card, target), mod, act\n",
    "\n",
    "def makeActionOneHot(act):\n",
    "    x = torch.zeros(6+6+5+37+37).float().cuda()\n",
    "    x[act.player] = 1\n",
    "    x[6+act.defender] = 1\n",
    "    x[6+6+verbs.index(act.verb)] = 1\n",
    "    card = act.card if act.card is not None else 36\n",
    "    target = act.target if act.target is not None else 36\n",
    "    x[6+6+5+card] = 1\n",
    "    x[6+6+5+37+target] = 1\n",
    "    return x\n",
    "\n",
    "class History:\n",
    "    def __init__(self, discount, forget):\n",
    "        self.hist = 5*[{}]\n",
    "        self.discount = discount\n",
    "        self.forget = forget\n",
    "        \n",
    "    def process(self, reward, act):\n",
    "        disc = 0\n",
    "        for a,d in zip([int(part) for part in act],self.hist):\n",
    "            for k in d.keys():\n",
    "                d[k] *= self.forget\n",
    "            if a in d:\n",
    "                d[a] += 1\n",
    "            else:\n",
    "                d[a] = 0\n",
    "            disc += d[a]\n",
    "        return reward - disc*self.discount\n",
    "\n",
    "nEpochs = 10_000\n",
    "running = []\n",
    "pPeriod = 100\n",
    "window = 50\n",
    "hist = History(2,0.95)\n",
    "\n",
    "for i in range(nEpochs):\n",
    "    optim.zero_grad()\n",
    "    xb, x = moves(g.board, g.attacker.hand, g.players.index(g.attacker), g.players.index(g.defender))\n",
    "    x = gen(xb)\n",
    "    action, mod, act = makeAction(x)\n",
    "    actOneHot = makeActionOneHot(action)\n",
    "    actionReward = g.action(action).detach()\n",
    "    reward = torch.sum(actionReward)\n",
    "    add = reward == 50\n",
    "    reward = hist.process(reward, act)\n",
    "    loss = sum([-(reward)*m.log_prob(a) for m,a in zip(mod,act)])\n",
    "    loss.backward()\n",
    "    if add and not gen.lookup(actOneHot):\n",
    "        gen.add(actOneHot)\n",
    "    optim.step()\n",
    "    running.append(reward)\n",
    "    if len(running) == window:\n",
    "        running.pop(0)\n",
    "    if i % pPeriod == 0:\n",
    "        print(f'epoch {i} running {sum(running)/len(running)}')\n",
    "        print(action.verb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "2d3a3d17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1.]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "running[-10:]\n",
    "# print(torch.stack(gen.notLegal[-10:]))\n",
    "print(gen.num)\n",
    "print(gen.legal[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "020925c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "013836 26.17921006037081\n",
      "0132136 17.842742822579773\n",
      "013336 15.198590524843553\n",
      "0131836 14.510441507120012\n",
      "0131236 13.964993451288487\n",
      "0132336 1.8996215775555378\n",
      "0133336 1.583071768619456\n",
      "013236 1.2731325898092947\n",
      "0132836 1.0348757202153298\n",
      "0131136 1.0054513079341796\n",
      "0132436 0.7994947495712481\n",
      "0131230 0.6744559581129893\n",
      "013815 0.6117180999749755\n",
      "0132113 0.5739762378493748\n",
      "5132136 0.5582661385478638\n",
      "013828 0.5439750549573139\n",
      "013813 0.31342453672908893\n",
      "013830 0.23930717852278607\n",
      "013310 0.2023022985967337\n",
      "0131228 0.1697567740825631\n"
     ]
    }
   ],
   "source": [
    "keys = sorted(hist.hist, key=hist.hist.get)\n",
    "keys.reverse()\n",
    "for k in keys[:20]:\n",
    "    print(k,hist.hist[k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22497f26",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
